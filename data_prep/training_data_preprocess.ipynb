{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T20:10:27.712922Z",
     "start_time": "2024-04-29T20:10:27.025633Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "data = pd.read_json('../data/preprocessed/combined_data.json')\n",
    "# where label is train_tr\n",
    "data = data[data['label'] == 'train_tr'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(5269, 6)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T20:10:28.476017Z",
     "start_time": "2024-04-29T20:10:28.472080Z"
    }
   },
   "id": "685e4cfd2a16cd91"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# METHODOLOGY: Make triplets by db_id where all negative examples are in the same db_id with 10 random negative examples\n",
    "\n",
    "# List to hold JSON strings\n",
    "jsonl_output = []\n",
    "\n",
    "# Grouping the dataframe by db_id\n",
    "for db_id, group in data.groupby('db_id'):\n",
    "    # Iterate over each row in the group\n",
    "    for i, row in group.iterrows():\n",
    "        # Get negative evidence, excluding the current row\n",
    "        neg_evidence = group[group.index != i]['evidence']\n",
    "        # If there are fewer than 10 negatives, take as many as are available; otherwise, sample 10\n",
    "        if len(neg_evidence) <= 10:\n",
    "            sampled_neg = neg_evidence.tolist()\n",
    "        else:\n",
    "            sampled_neg = neg_evidence.sample(10).tolist()  # Each sample is independent\n",
    "\n",
    "        # Constructing the JSON object for each row\n",
    "        json_object = {\n",
    "            'set': {\n",
    "                'query': row['question'],\n",
    "                'pos': [row['evidence']],\n",
    "                'neg': sampled_neg\n",
    "            }\n",
    "        }\n",
    "        jsonl_output.append(json_object)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T20:10:40.595730Z",
     "start_time": "2024-04-29T20:10:39.399925Z"
    }
   },
   "id": "f222bd946c660d9c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# save to jsonl with indent\n",
    "import json\n",
    "with open('../data/preprocessed/training_evidence_triplet_data.json', 'w') as f:\n",
    "    for json_object in jsonl_output:\n",
    "        json.dump(json_object, f)\n",
    "        f.write('\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T20:11:16.793148Z",
     "start_time": "2024-04-29T20:11:16.693249Z"
    }
   },
   "id": "ef6460506cfad980"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# METHODOLOGY: Make triplets by db_id where all negative examples are in the same db_id with 10 random negative examples\n",
    "\n",
    "# List to hold JSON strings\n",
    "jsonl_output = []\n",
    "\n",
    "# Grouping the dataframe by db_id\n",
    "for db_id, group in data.groupby('db_id'):\n",
    "    # Iterate over each row in the group\n",
    "    for i, row in group.iterrows():\n",
    "        # Get negative evidence, excluding the current row\n",
    "        neg_evidence = group[group.index != i]['SQL']\n",
    "        # If there are fewer than 10 negatives, take as many as are available; otherwise, sample 10\n",
    "        if len(neg_evidence) <= 10:\n",
    "            sampled_neg = neg_evidence.tolist()\n",
    "        else:\n",
    "            sampled_neg = neg_evidence.sample(10).tolist()  # Each sample is independent\n",
    "\n",
    "        # Constructing the JSON object for each row\n",
    "        json_object = {\n",
    "            'set': {\n",
    "                'query': row['question'],\n",
    "                'pos': [row['SQL']],\n",
    "                'neg': sampled_neg\n",
    "            }\n",
    "        }\n",
    "        jsonl_output.append(json_object)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T20:11:40.883281Z",
     "start_time": "2024-04-29T20:11:39.687892Z"
    }
   },
   "id": "7045d34a1d5d8105"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# save to jsonl with indent\n",
    "import json\n",
    "with open('../data/preprocessed/training_sql_triplet_data.json', 'w') as f:\n",
    "    for json_object in jsonl_output:\n",
    "        json.dump(json_object, f)\n",
    "        f.write('\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T20:11:51.758101Z",
     "start_time": "2024-04-29T20:11:51.621995Z"
    }
   },
   "id": "dc5d392817aaa515"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
